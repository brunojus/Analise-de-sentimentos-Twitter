mutate(sentiment = ifelse(sentiment < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, post_link, post_type, sentiment) %>%
# converter para formato wide
spread(sentiment, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
df_comments_wide <- df_comments %>%
filter(sentiment.y != 0) %>%
mutate(sentiment.y = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
df_comments_wide <- df_comments %>%
filter(sentiment != 0) %>%
mutate(sentiment = ifelse(sentiment < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, post_link, post_type, sentiment) %>%
# converter para formato wide
spread(sentiment, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
df_comments_wide <- df_comments %>%
filter(sentiment.y != 0) %>%
mutate(sentiment = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, post_link, post_type, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
df_comments_wide <- df_comments %>%
filter(sentiment.y != 0) %>%
mutate(sentiment = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
View(df_comments_unnested)
df_comments_wide <- df_comments %>%
filter(sentiment.y != 0) %>%
mutate(sentiment = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentiment.y = positivo - negativo) %>%
ungroup() %>%
arrange(data)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y != 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
View(df_comments_wide)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y != 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(date, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y != 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
head(df_comments_wide) %>% knitr::kable()
df_comments_wide %>%
arrange(sentimento) %>%
filter(row_number() == 1 | row_number() == nrow(df_comments_wide)) %>%
knitr::kable()
df_comments %>%
mutate(
temer = str_detect(str_to_lower(text), "temer"),
lula = str_detect(str_to_lower(text), "lula"),
pmdb = str_detect(str_to_lower(text), "pmdb"),
psdb = str_detect(str_to_lower(text), "psdb"),
pt = str_detect(str_to_lower(text), "pt"),
dilma = str_detect(str_to_lower(text), "dilma"),
doria = str_detect(str_to_lower(text), "doria"),
governo = str_detect(str_to_lower(text), "governo"),
bolsonaro = str_detect(str_to_lower(text), "bolsonaro")
) %>%
gather(termo, eh_presente, temer:bolsonaro) %>%
filter(eh_presente) %>%
group_by(termo) %>%
summarise(sentiment = mean(sentiment)) %>%
ggplot(aes(x = termo, y = sentiment)) +
geom_col(fill = "#C10534")
df_comments %>%
mutate(
temer = str_detect(str_to_lower(text), "temer"),
lula = str_detect(str_to_lower(text), "lula"),
pmdb = str_detect(str_to_lower(text), "pmdb"),
psdb = str_detect(str_to_lower(text), "psdb"),
pt = str_detect(str_to_lower(text), "pt"),
dilma = str_detect(str_to_lower(text), "dilma"),
doria = str_detect(str_to_lower(text), "doria"),
governo = str_detect(str_to_lower(text), "governo"),
bolsonaro = str_detect(str_to_lower(text), "bolsonaro")
) %>%
gather(termo, eh_presente, temer:bolsonaro) %>%
filter(eh_presente) %>%
group_by(termo) %>%
summarise(sentiment = mean(sentiment)) %>%
ggplot(aes(x = termo, y = sentiment.y)) +
geom_col(fill = "#C10534")
df_comments %>%
mutate(
temer = str_detect(str_to_lower(text), "temer"),
lula = str_detect(str_to_lower(text), "lula"),
pmdb = str_detect(str_to_lower(text), "pmdb"),
psdb = str_detect(str_to_lower(text), "psdb"),
pt = str_detect(str_to_lower(text), "pt"),
dilma = str_detect(str_to_lower(text), "dilma"),
doria = str_detect(str_to_lower(text), "doria"),
governo = str_detect(str_to_lower(text), "governo"),
bolsonaro = str_detect(str_to_lower(text), "bolsonaro")
) %>%
gather(termo, eh_presente, temer:bolsonaro) %>%
filter(eh_presente) %>%
group_by(termo) %>%
summarise(sentiment.y = mean(sentiment.y)) %>%
ggplot(aes(x = termo, y = sentiment.y)) +
geom_col(fill = "#C10534")
df_comments %>%
mutate(
temer = str_detect(str_to_lower(text), "temer"),
lula = str_detect(str_to_lower(text), "lula"),
pmdb = str_detect(str_to_lower(text), "pmdb"),
psdb = str_detect(str_to_lower(text), "psdb"),
pt = str_detect(str_to_lower(text), "pt"),
dilma = str_detect(str_to_lower(text), "dilma"),
doria = str_detect(str_to_lower(text), "doria"),
governo = str_detect(str_to_lower(text), "governo"),
bolsonaro = str_detect(str_to_lower(text), "bolsonaro")
) %>%
gather(termo, eh_presente, temer:bolsonaro) %>%
filter(eh_presente) %>%
group_by(termo) %>%
summarise(sentiment.y = mean(sentiment.y)) %>%
ggplot(aes(x = termo, y = sentiment.y)) +
geom_col(fill = "#C10534")
View(df_comments_wide)
ggplot(aes(x = index, y = sentimento))
df_comments_wide %>%
mutate(index = row_number()) %>%
ggplot(aes(x = index, y = sentimento)) +
geom_col(aes(fill = post_type)) +
scale_y_continuous(breaks = seq(-60, 60, 20), limits = c(-60, 60)) +
labs(x = "Índice da publicação", y = "Sentimento",
fill = NULL, title = "Evolução do sentimento em publicações do Sensacionalista")
df_comments_wide %>%
mutate(index = row_number()) %>%
ggplot(aes(x = index, y = sentimento)) +
geom_col(aes(fill = date)) +
scale_y_continuous(breaks = seq(-60, 60, 20), limits = c(-60, 60)) +
labs(x = "Índice da publicação", y = "Sentimento",
fill = NULL, title = "Evolução do sentimento em publicações do Sensacionalista")
get_word_sentiment("temer")
df_comments_wide$sentimento
if(df_comments_wide$sentimento == 0)
cf
filter(df_comments_wide,sentimento==0)
teste <- filter(df_comments_wide,sentimento==0)
View(teste)
View(df_comments_unnested)
df_comments_wide2 <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = 'neutro' %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
s
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y == 0, "neutro", "neutral")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
df_comments_wide2 <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y == 0, "neutro", "neutral")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
df_comments_wide2 <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y == 0, "neutro", "neutral")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
ungroup() %>%
arrange(date)
View(df_comments_wide2)
View(df_comments_unnested)
View(df_comments_wide)
df_comments_wide2 <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment == 0) %>%
d
df_comments['sentiment.y'==0]
df_comments['sentiment.y']
View(df_comments)
write.table(df_comments, file = "MyData.txt",row.names=FALSE, na="",col.names=FALSE, sep="\t")
write.table(df_comments, file = "MyData.txt",row.names=FALSE, na="",col.names=TRUE, sep="\t")
write.table(df_comments, file = "MyData.txt",row.names=TRUE, na="",col.names=TRUE, sep="\t")
write.table(df_comments, file = "MyData.txt",row.names=TRUE, na="",col.names=TRUE, sep="\t")
write.table(df_comments, file = "MyData.txt",row.names=TRUE, na="",col.names=TRUE, sep="\t")
source('~/Documents/artigo/R/teste.R')
install.packages("tidytext")
install.packages("tidyverse")
source('~/Documents/artigo/R/teste.R')
install.packages("ggExtra")
source('~/Documents/artigo/R/teste.R')
View(df_comments)
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
df_comments_unnested %>%
left_join(op30, by = "term") %>%
left_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
select(comment_id, term, polarity, lex_polarity) %>%
head(10)
df_comments_unnested <- df_comments_unnested %>%
inner_join(op30, by = "term") %>%
inner_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
group_by(comment_id) %>%
summarise(
comment_sentiment_op = sum(polarity),
comment_sentiment_lex = sum(lex_polarity),
n_words = n()
) %>%
ungroup() %>%
rowwise() %>%
mutate(
most_neg = min(comment_sentiment_lex, comment_sentiment_op),
most_pos = max(comment_sentiment_lex, comment_sentiment_op)
)
head(df_comments_unnested)
View(df_comments)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y == 0, "neutro", "neutral")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)> s
p <- df_comments_unnested %>%
ggplot(aes(x = comment_sentiment_op, y = comment_sentiment_lex)) +
geom_point(aes(color = n_words)) +
scale_color_continuous(low = "green", high = "red") +
labs(x = "Polaridade no OpLexicon", y = "Polaridade no SentiLex") +
#geom_smooth(method = "lm") +
geom_vline(xintercept = 0, linetype = "dashed") +
geom_hline(yintercept = 0, linetype = "dashed")
p
df_comments_unnested %<>% filter(between(comment_sentiment_op, -10, 10))
# comentario mais positivo da historia do sensacionalista
most_pos <- which.max(df_comments_unnested$most_pos)
most_neg <- which.min(df_comments_unnested$most_neg)
# mais positivo
cat(df_comments$message[df_comments$comment_id == df_comments_unnested$comment_id[most_pos]])
View(df_comments)
df_comments_unnested %<>% filter(between(comment_sentiment_op, -10, 10))
# comentario mais positivo da historia do sensacionalista
most_pos <- which.max(df_comments_unnested$most_pos)
most_neg <- which.min(df_comments_unnested$most_neg)
# mais positivo
cat(df_comments$text[df_comments$comment_id == df_comments_unnested$comment_id[most_pos]])
df_comments %<>% inner_join(
df_comments_unnested %>% select(comment_id, sentiment = comment_sentiment_op),
by = "comment_id"
)
View(df_comments)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment != 0) %>%
# converter numerico para categorico
mutate(sentiment = ifelse(sentiment < 0, "negativo", "positivo")) %>%
# agrupar os dados
count(data, post_link, post_type, sentiment) %>%
# converter para formato wide
spread(sentiment, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(data)
head(df_comments_wide) %>% knitr::kable()
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
View(df_comments_unnested)
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
df_comments_unnested %>%
left_join(op30, by = "term") %>%
left_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
select(comment_id, term, polarity, lex_polarity) %>%
head(10)
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
df_comments_unnested %>%
left_join(op30, by = "term") %>%
left_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
select(comment_id, term, polarity, lex_polcarity) %>%
head(10)sdsd
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
df_comments_unnested <- df_comments %>% unnest_tokens(term, text)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
df_comments_unnested %>%
left_join(op30, by = "term") %>%
left_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
select(comment_id, term, polarity, lex_polarity) %>%
head(10)
df_comments_unnested <- df_comments_unnested %>%
inner_join(op30, by = "term") %>%
inner_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
group_by(comment_id) %>%
summarise(
comment_sentiment_op = sum(polarity),
comment_sentiment_lex = sum(lex_polarity),
n_words = n()
) %>%
ungroup() %>%
rowwise() %>%
mutate(
most_neg = min(comment_sentiment_lex, comment_sentiment_op),
most_pos = max(comment_sentiment_lex, comment_sentiment_op)
)
head(df_comments_unnested)
df_comments_wide <- df_comments %>%
# filtrar fora palavras neutras
filter(sentiment.y == 0) %>%
# converter numerico para categorico
mutate(sentiment.y = ifelse(sentiment.y == 0, "neutro", "neutral")) %>%
# agrupar os dados
count(date, text, permalink, sentiment.y) %>%
# converter para formato wide
spread(sentiment.y, n, fill = 0) %>%
mutate(sentimento = positivo - negativo) %>%
ungroup() %>%
arrange(date)
View(df_comments)
View(df_comments_unnested)
# criar ID unica para cada comentario
df_comments %<>% mutate(comment_id = row_number())
# usar funçao do tidytext para criar uma linha para cada palavra de um comentario
df_comments_unnested <- df_comments %>% unnest_tokens(term, message)
df_comments_unnested %>%
select(comment_id, term) %>%
head(20)
df_comments_unnested %>%
left_join(op30, by = "term") %>%
left_join(sent %>% select(term, lex_polarity = polarity), by = "term") %>%
select(comment_id, term, polarity, lex_polarity) %>%
head(10)
View(df_comments_unnested)
library(tidyverse) # pq nao da pra viver sem
library(ggExtra)
library(magrittr) # <3
library(lubridate)
library(stringr) # essencial para trabalhar com textos
library(tidytext) # um dos melhores pacotes para text mining
library(lexiconPT)
data("oplexicon_v3.0")
data("sentiLex_lem_PT02")
op30 <- oplexicon_v3.0
sent <- sentiLex_lem_PT02
df_comments <- read.delim("~/Documents/artigo/R/Aecio1_oplexiconLimpo.txt", stringsAsFactors=FALSE)
df_comments %<>% mutate(comment_id = row_number())
