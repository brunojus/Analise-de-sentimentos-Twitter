{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import chain\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = [w for w in tokens if not w in stopwords.words('portuguese')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilma1turno=pd.read_csv(\"Dados Treinamento/clasdilma1.txt\",delimiter=\"\\t\",encoding='latin-1')\n",
    "dilma1turno['text']= dilma1turno['text'].replace(r'goo\\S+', '', regex=True).replace(r'pic\\S+', '', regex=True).replace(r'ow\\S+', '', regex=True).replace(r'fb\\S+','',regex=True)\n",
    "subset = dilma1turno[['text', 'sentiment']]\n",
    "tuples_dilma_1turno = [tuple(x) for x in subset.values]\n",
    "train_set, test_set = tuples_dilma_1turno[15000:], tuples_dilma_1turno[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dilma1turno['text']: # iterate over word_list\n",
    "    if word in stopwords.words('portuguese'): \n",
    "        dilma1turno['text'].remove(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        geraldo alckmin reeleito governador de sao pau...\n",
       "1                           turno dilma e aecio dois bosta\n",
       "2        dilma rousseff  pt  e aecio neves  psdb  vao d...\n",
       "3                                     dilma de novo nao ne\n",
       "4        vai ser tao apertado que os votos da luciana g...\n",
       "5        voces idolatrando aecio  no minimo  nao sabem ...\n",
       "6        segundo turno da treva   >   com    das urnas ...\n",
       "7                                         dilma e aecio af\n",
       "8        pobre...so pensa em bolsa familia so isso q di...\n",
       "9        essa coisa dos nordestino votar na dilma so po...\n",
       "10                              turno dilma e aecio neves \n",
       "11       aecio ta so   atras de dilma  vamos virar isso...\n",
       "12       eu falei que ia dar aecio cheira po e dilma no...\n",
       "13       a unica coisa que n queria era alckmin governa...\n",
       "14       affs depois o povo mete o pau na dilma e agora...\n",
       "15       aaaargh que odio desse povo brasileiro  faz pr...\n",
       "16       confirmado aecio neves x dilma no segundo turn...\n",
       "17                 a dilma ganhou por causa dos pobres ...\n",
       "18                      turno confirmado    dilma x aecio.\n",
       "19                         dilma perde no segundo turno...\n",
       "20              aecio e dilma segundo turno  aecioconfirma\n",
       "21       toma porra to revoltada com esse pais retardad...\n",
       "22       antigamente so filhos de ricos se formavam  gr...\n",
       "23                                 e dilma e dilma e dilma\n",
       "24         a dilma pegou um pais ja estabilizado no sis...\n",
       "25          tanto faz aecio ou dilma nenhum ai prestar msm\n",
       "26              partiu segundo turno    dilma vs aecio    \n",
       "27       dilma e aecio estao garantidos no segundo turn...\n",
       "28                              0 turno aecio e dilma puts\n",
       "29        verdade vamos ver quem marina e os outros vao...\n",
       "                               ...                        \n",
       "50728    eu quero e saber quem via pro ÃÂÃÂÃÂÃÂ...\n",
       "50729    sacanagem  estao segurando os resultados presi...\n",
       "50730    imagens de dilma   marina e aecio na infancia ...\n",
       "50731      lu ou dilma as melhores opcoes marina uma pl...\n",
       "50732    nossa tirar a dilma pra por o aecio  vao se foder\n",
       "50733       quero aecio no segundo turno com a mamae dilma\n",
       "50734       lula ' dilma quer debater corrupcao com aec...\n",
       "50735    internautas declaram apoio e dilma e marina sa...\n",
       "50736    sou do nordeste e nao votei na dilma e nem nos...\n",
       "50737    voce nao querem aecio  nao querem dilma   nao ...\n",
       "50738    internautas declaram apoio  e dilma e marina s...\n",
       "50739                         secao  dilma  marina  aecio \n",
       "50740    a tag marinabrasil estava disparado na frente ...\n",
       "50741    sobre morgar com um boyzinho pq ele votou em d...\n",
       "50742               caindo a dilma hoje nada mais importa \n",
       "50743             apuracao dilma  aecio  marina  ben  cpm \n",
       "50744    caracas pelo menos na secao que eu trabalhei d...\n",
       "50745    dilma   minha querida  se voce for eleita me a...\n",
       "50746                                   dilma tu nao ganha\n",
       "50747     m.facebook.com/l.php u http  a f f ÃÂÃÂÃ...\n",
       "50748      olha  acho q e uma mistura dos dois > gananc...\n",
       "50749    eu so to vendo papel com aecio dando de lavada...\n",
       "50750    reclama que o pdsb ta muito tempo no poder em ...\n",
       "50751     so me resta rezar para que dilma meta o pe da...\n",
       "50752    psdb saudado pt vaiado e o porque de dilma a f...\n",
       "50753    se o aecio ganhar nao tem nada errado  agora s...\n",
       "50754     entre dilma   marina e aecio  vou pela primei...\n",
       "50755    causo de que ela nao gosta da dilma heheh rt  ...\n",
       "50756            caramba  imagina se a dilma for reeleita \n",
       "50757    ate agora tentando entender aquelas pessoas qu...\n",
       "Name: text, Length: 50758, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilma1turno['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(chain(*[word_tokenize(i[0].lower()) for i in test_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5d39b5500280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-5d39b5500280>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-5d39b5500280>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0monly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \"\"\"\n\u001b[0;32m--> 802\u001b[0;31m     \u001b[0mresource_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_resource_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m     \u001b[0mresource_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mnormalize_resource_url\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_resource_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# the resource url has no protocol, use the nltk protocol by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36msplit_resource_url\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/C:/home/nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_set = [({i:(i in word_tokenize(sentence.lower())) for i in vocabulary},tag) for sentence, tag in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"Odeio a Dilma bandida\"\n",
    "featurized_test_sentence =  {i:(i in word_tokenize(test_sentence.lower())) for i in vocabulary}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"test_sent:\",test_sentence\n",
    "print \"tag:\",classifier.classify(featurized_test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
