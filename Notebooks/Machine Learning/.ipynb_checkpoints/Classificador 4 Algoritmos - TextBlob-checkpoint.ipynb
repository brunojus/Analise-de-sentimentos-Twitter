{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier, SklearnClassifier, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk import precision\n",
    "from nltk.metrics import *\n",
    "from nltk.metrics import spearman\n",
    "from nltk.metrics import paice\n",
    "from nltk.metrics import scores\n",
    "import csv\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TextBlob'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TextBlob\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posdata = []\n",
    "with open('/home/bruno/Documents/artigo/R/Sentiment/positive_textblob.csv', 'rt') as myfile:    \n",
    "    reader = csv.reader(myfile, delimiter='\\t')\n",
    "    for val in reader:\n",
    "        posdata.append(val[0])        \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neudata = []\n",
    "with open('/home/bruno/Documents/artigo/R/Sentiment/neutral_textblob.csv', 'rt') as myfile:    \n",
    "    reader = csv.reader(myfile, delimiter='\\t')\n",
    "    for val in reader:\n",
    "        neudata.append(val[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negdata = []\n",
    "with open('/home/bruno/Documents/artigo/R/Sentiment/negative_textblob.csv', 'rt') as myfile:    \n",
    "    reader = csv.reader(myfile, delimiter='\\t')\n",
    "    for val in reader:\n",
    "        negdata.append(val[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(data):    \n",
    "    data_new = []\n",
    "    for word in data:\n",
    "        word_filter = [i.lower() for i in word.split()]\n",
    "        data_new.append(word_filter)\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split_sentiment(data):\n",
    "    data_new = []\n",
    "    for (word, sentiment) in data:\n",
    "        word_filter = [i.lower() for i in word.split()]\n",
    "        data_new.append((word_filter, sentiment))\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):    \n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopset = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_filtered_word_feats(words):\n",
    "    return dict([(word, True) for word in words if word not in stopset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    \"\"\"\n",
    "    print words\n",
    "    for ngram in itertools.chain(words, bigrams): \n",
    "        if ngram not in stopset: \n",
    "            print ngram\n",
    "    exit()\n",
    "    \"\"\"    \n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_word_feats_stopwords(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    \"\"\"\n",
    "    print words\n",
    "    for ngram in itertools.chain(words, bigrams): \n",
    "        if ngram not in stopset: \n",
    "            print ngram\n",
    "    exit()\n",
    "    \"\"\"    \n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams) if ngram not in stopset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------\n",
      "SINGLE FOLD RESULT (Naive Bayes)\n",
      "---------------------------------------\n",
      "accuracy: 0.8265844356082123\n",
      "precision 0.839354629970456\n",
      "recall 0.7951298332766817\n",
      "f-measure 0.8073270378757568\n",
      "\n",
      "---------------------------------------\n",
      "SINGLE FOLD RESULT (SVM)\n",
      "---------------------------------------\n",
      "accuracy: 0.9440882901890774\n",
      "precision 0.9436332677323206\n",
      "recall 0.9375426294598688\n",
      "f-measure 0.9403845871784844\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.390\n",
      "             2          -1.09837        0.709\n",
      "         Final          -1.09813        0.709\n",
      "\n",
      "---------------------------------------\n",
      "SINGLE FOLD RESULT (Maximum Entropy)\n",
      "---------------------------------------\n",
      "accuracy: 0.7040493386350726\n",
      "precision 0.7968633166187084\n",
      "recall 0.6097840360061556\n",
      "f-measure 0.5583554767994044\n",
      "\n",
      "---------------------------------------\n",
      "SINGLE FOLD RESULT (Decision Tree)\n",
      "---------------------------------------\n",
      "accuracy: 0.6403473180232087\n",
      "precision 0.6932039613132183\n",
      "recall 0.5698891874786532\n",
      "f-measure 0.5553640139663818\n",
      "\n",
      "---------------------------------------\n",
      "N-FOLD CROSS VALIDATION RESULT (Naive Bayes)\n",
      "---------------------------------------\n",
      "accuracy: 0.812114448051948\n",
      "precision 0.8236923385180206\n",
      "recall 0.8650559542061251\n",
      "f-measure 0.7936837514920416\n",
      "\n",
      "---------------------------------------\n",
      "N-FOLD CROSS VALIDATION RESULT (SVM)\n",
      "---------------------------------------\n",
      "accuracy: 0.9307426948051949\n",
      "precision 0.928798952925708\n",
      "recall 0.9352912171295626\n",
      "f-measure 0.9262325267657779\n",
      "\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.390\n",
      "             2          -1.09837        0.707\n",
      "         Final          -1.09813        0.707\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.390\n",
      "             2          -1.09837        0.707\n",
      "         Final          -1.09813        0.707\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.389\n",
      "             2          -1.09837        0.704\n",
      "         Final          -1.09813        0.704\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.389\n",
      "             2          -1.09837        0.704\n",
      "         Final          -1.09813        0.704\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.392\n",
      "             2          -1.09837        0.708\n",
      "         Final          -1.09813        0.708\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.391\n",
      "             2          -1.09837        0.707\n",
      "         Final          -1.09813        0.707\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.391\n",
      "             2          -1.09837        0.707\n",
      "         Final          -1.09813        0.707\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.390\n",
      "             2          -1.09837        0.705\n",
      "         Final          -1.09813        0.705\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.389\n",
      "             2          -1.09837        0.707\n",
      "         Final          -1.09813        0.707\n",
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.390\n",
      "             2          -1.09837        0.705\n",
      "         Final          -1.09813        0.705\n",
      "---------------------------------------\n",
      "N-FOLD CROSS VALIDATION RESULT (Maximum Entropy)\n",
      "---------------------------------------\n",
      "accuracy: 0.6884943181818183\n",
      "precision 0.7872849826472238\n",
      "recall 0.903303186040418\n",
      "f-measure 0.5465321298406185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classifier(featx):\n",
    "    \n",
    "    negfeats = [(featx(f), 'neg') for f in word_split(negdata)]\n",
    "    posfeats = [(featx(f), 'pos') for f in word_split(posdata)]\n",
    "    neufeats = [(featx(f), 'neu') for f in word_split(neudata)]    \n",
    "    \n",
    "    negcutoff = int(len(negfeats)*3/4)\n",
    "    poscutoff = int(len(posfeats)*3/4)\n",
    "    neucutoff = int(len(neufeats)*3/4)\n",
    "    \n",
    " \n",
    "    trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff] + neufeats[:neucutoff]\n",
    "    testfeats = negfeats[negcutoff:] + posfeats[poscutoff:] + neufeats[neucutoff:]\n",
    "    \n",
    "    # using 3 classifiers\n",
    "    classifier_list = ['nb', 'svm','maxent','decision_tree']     \n",
    "        \n",
    "    for cl in classifier_list:\n",
    "        \n",
    "        if cl == 'maxent':\n",
    "            classifierName = 'Maximum Entropy'\n",
    "            algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "            classifier = nltk.MaxentClassifier.train(trainfeats, algorithm,max_iter=3)\n",
    "        elif cl == 'svm':\n",
    "            classifierName = 'SVM'\n",
    "            classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "            classifier.train(trainfeats)\n",
    "            \n",
    "        elif cl == 'decision_tree':\n",
    "            classifierName = 'Decision Tree'\n",
    "            classifier = DecisionTreeClassifier.train(trainfeats, binary=True, depth_cutoff=20, support_cutoff=20, entropy_cutoff=0.01)\n",
    "            \n",
    "        else:\n",
    "            classifierName = 'Naive Bayes'\n",
    "            classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "            \n",
    "        refsets = collections.defaultdict(set)\n",
    "        testsets = collections.defaultdict(set)\n",
    " \n",
    "        for i, (feats, label) in enumerate(testfeats):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    " \n",
    "        accuracy = nltk.classify.util.accuracy(classifier, testfeats)\n",
    "    \n",
    "        pos_precision = scores.precision(refsets['pos'], testsets['pos'])\n",
    "        pos_recall = scores.recall(refsets['pos'], testsets['pos'])\n",
    "        pos_fmeasure = scores.f_measure(refsets['pos'], testsets['pos'])\n",
    "        \n",
    "        neg_precision = scores.precision(refsets['neg'], testsets['neg'])\n",
    "        neg_recall = scores.recall(refsets['neg'], testsets['neg'])\n",
    "        neg_fmeasure =  scores.f_measure(refsets['neg'], testsets['neg'])\n",
    "        \n",
    "        neu_precision = scores.precision(refsets['neu'], testsets['neu'])\n",
    "        neu_recall = scores.recall(refsets['neu'], testsets['neu'])\n",
    "        neu_fmeasure = scores.f_measure(refsets['neu'], testsets['neu'])\n",
    "        \n",
    "        print ('')\n",
    "        print ('---------------------------------------')\n",
    "        print ('SINGLE FOLD RESULT ' + '(' + classifierName + ')')\n",
    "        print ('---------------------------------------')\n",
    "        print ('accuracy:', accuracy)\n",
    "        print ('precision', (pos_precision + neg_precision + neu_precision) / 3)\n",
    "        print ('recall', (pos_recall + neg_recall + neu_recall) / 3)\n",
    "        print ('f-measure', (pos_fmeasure + neg_fmeasure + neu_fmeasure) / 3)    \n",
    "                \n",
    "        #classifier.show_most_informative_features()\n",
    "    \n",
    "    print ('')\n",
    "    \n",
    "    ## CROSS VALIDATION\n",
    "    \n",
    "    trainfeats = negfeats + posfeats + neufeats   \n",
    "    \n",
    "    # SHUFFLE TRAIN SET\n",
    "    # As in cross validation, the test chunk might have only negative or only positive data    \n",
    "    random.shuffle(trainfeats)    \n",
    "    n = 10 # 5-fold cross-validation    \n",
    "    \n",
    "    for cl in classifier_list:\n",
    "        \n",
    "        subset_size = int(len(trainfeats) / n)\n",
    "        accuracy = []\n",
    "        \n",
    "        pos_precision = []\n",
    "        pos_recall = []\n",
    "        pos_fmeasure = []\n",
    "        \n",
    "        neg_precision = []\n",
    "        neg_recall = []\n",
    "        neg_fmeasure = []\n",
    "        \n",
    "        neu_precision = []\n",
    "        neu_recall = []\n",
    "        neu_fmeasure = []\n",
    "\n",
    "        cv_count = 1\n",
    "        for i in range(n):        \n",
    "            testing_this_round = trainfeats[i*subset_size:][:subset_size]\n",
    "            training_this_round = trainfeats[:i*subset_size] + trainfeats[(i+1)*subset_size:]\n",
    "            \n",
    "            if cl == 'maxent':\n",
    "                classifierName = 'Maximum Entropy'\n",
    "                algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "                classifier = nltk.MaxentClassifier.train(training_this_round, algorithm,max_iter=3)\n",
    "            elif cl == 'svm':\n",
    "                classifierName = 'SVM'\n",
    "                classifier = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "                classifier.train(training_this_round)\n",
    "            \n",
    "            elif cl == 'decision_tree':\n",
    "                classifierName = 'Decision Tree'\n",
    "                classifier = DecisionTreeClassifier.train(training_this_round, binary=True, depth_cutoff=20, support_cutoff=20, entropy_cutoff=0.01)\n",
    "            else:\n",
    "                classifierName = 'Naive Bayes'\n",
    "                classifier = NaiveBayesClassifier.train(training_this_round)\n",
    "                    \n",
    "            refsets = collections.defaultdict(set)\n",
    "            testsets = collections.defaultdict(set)\n",
    "            for i, (feats, label) in enumerate(testing_this_round):\n",
    "                refsets[label].add(i)\n",
    "                observed = classifier.classify(feats)\n",
    "                testsets[observed].add(i)\n",
    "            \n",
    "            cv_accuracy = nltk.classify.util.accuracy(classifier, testing_this_round)\n",
    "            cv_pos_precision = scores.precision(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_recall = scores.recall(refsets['pos'], testsets['pos'])\n",
    "            cv_pos_fmeasure = scores.f_measure(refsets['pos'], testsets['pos'])\n",
    "            \n",
    "            cv_neg_precision = scores.precision(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_recall = scores.recall(refsets['neg'], testsets['neg'])\n",
    "            cv_neg_fmeasure =  scores.f_measure(refsets['neg'], testsets['neg'])\n",
    "            \n",
    "            cv_neu_precision = scores.precision(refsets['neu'], testsets['neu'])\n",
    "            cv_neu_recall = scores.recall(refsets['neu'], testsets['neu'])\n",
    "            cv_neu_fmeasure = scores.f_measure(refsets['neu'], testsets['neu'])\n",
    "                    \n",
    "            accuracy.append(cv_accuracy)\n",
    "            pos_precision.append(cv_pos_precision)\n",
    "            pos_recall.append(cv_pos_recall)\n",
    "            pos_fmeasure.append(cv_pos_fmeasure)\n",
    "\n",
    "            neg_precision.append(cv_neg_precision)\n",
    "            neg_recall.append(cv_neg_recall)\n",
    "            neg_fmeasure.append(cv_neg_fmeasure)\n",
    "            \n",
    "            neu_precision.append(cv_neu_precision)\n",
    "            neu_recall.append(cv_neu_recall)\n",
    "            neu_fmeasure.append(cv_neu_fmeasure)\n",
    "            \n",
    "            cv_count += 1\n",
    "                \n",
    "        print ('---------------------------------------')\n",
    "        print ('N-FOLD CROSS VALIDATION RESULT ' + '(' + classifierName + ')')\n",
    "        print ('---------------------------------------')\n",
    "        print ('accuracy:', sum(accuracy) / n)\n",
    "        print ('precision', (sum(pos_precision)/n + sum(neg_precision)/n + sum(neu_precision)/n) / 3)\n",
    "        print ('recall',  (sum(pos_recall)/n + sum(neg_recall)/n + sum(neu_precision)/n) / 3)\n",
    "        print ('f-measure', (sum(pos_fmeasure)/n + sum(neg_fmeasure)/n + sum(neu_fmeasure)/n) / 3)\n",
    "        print ('')\n",
    "    \n",
    "        \n",
    "evaluate_classifier(word_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
